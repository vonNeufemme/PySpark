{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b672032b",
   "metadata": {},
   "source": [
    "# PySpark Basics\n",
    "\n",
    "- PySpark Dataframe\n",
    "- Reading the dataset\n",
    "- Checking the datatypes of the columns (schema)\n",
    "- Selecting columns and indexing\n",
    "- Checking describe options similar to pandas\n",
    "- Adding columns\n",
    "- Dropping columns\n",
    "- Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadd977",
   "metadata": {},
   "source": [
    "## 0 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b21f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.2.0.tar.gz (281.3 MB)\n",
      "Collecting py4j==0.10.9.2\n",
      "  Using cached py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=8b94019ab4d1088e8528ec8956d93cf85ec1e5b7e30a83364f121651899a234b\n",
      "  Stored in directory: c:\\users\\appdata\\local\\pip\\cache\\wheels\\2f\\f8\\95\\2ad14a4614b4a9f645ee928fbbd057b1b254c67adb494c9a58\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633ca557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70bf38",
   "metadata": {},
   "source": [
    "## 1. Start SparkSession and Load data\n",
    "\n",
    "Syntax - start Session\n",
    "- `SparkSession.builder.appName('df').getOrCreate()`\n",
    "- `spark.read.option('header', 'true').csv(file_path, inferSchema=True)`\n",
    "- `spark.read.csv(file_path, header=True, inferSchema=True)`\n",
    "\n",
    "Syntax - read data\n",
    "- `df.show(num)`\n",
    "- `df.head(num)`\n",
    "- `df.printSchema()`\n",
    "- `df.describe()`\n",
    "- `df.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edae983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-B85K7A6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x224b66668e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('DataFrame').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f4f0689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "| keyword|freq_2021|\n",
      "+--------+---------+\n",
      "|    food|      540|\n",
      "|  drying|      341|\n",
      "| quality|      264|\n",
      "|   plant|      214|\n",
      "|products|      188|\n",
      "+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "df_pyspark = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "df_pyspark = spark.read.option('header', 'true').csv(file_path, inferSchema=True)\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a5f58c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- keyword: string (nullable = true)\n",
      " |-- freq_2021: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Check the schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f48cf7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['keyword', 'freq_2021']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0cf9b957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(keyword='food', freq_2021=540),\n",
       " Row(keyword='drying', freq_2021=341),\n",
       " Row(keyword='quality', freq_2021=264),\n",
       " Row(keyword='plant', freq_2021=214),\n",
       " Row(keyword='products', freq_2021=188)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfd0190",
   "metadata": {},
   "source": [
    "## 2. Reading dataset\n",
    "\n",
    "Syntax\n",
    "- `df_pyspark.show()`\n",
    "- `df.select('keyword', 'freq_2021').show()`\n",
    "- `df.select(['keyword', 'freq_2021']).show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c0167d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|    keyword|freq_2021|\n",
      "+-----------+---------+\n",
      "|       food|      540|\n",
      "|     drying|      341|\n",
      "|    quality|      264|\n",
      "|      plant|      214|\n",
      "|   products|      188|\n",
      "|     higher|      177|\n",
      "|       data|      177|\n",
      "| properties|      173|\n",
      "|     health|      171|\n",
      "|      water|      170|\n",
      "|development|      162|\n",
      "|      total|      160|\n",
      "|       risk|      157|\n",
      "|    control|      150|\n",
      "|    species|      150|\n",
      "|  potential|      147|\n",
      "|       acid|      147|\n",
      "|  increased|      142|\n",
      "| production|      139|\n",
      "|temperature|      137|\n",
      "+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()\n",
    "df.select('keyword', 'freq_2021').show()\n",
    "df.select(['keyword', 'freq_2021']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1455ed58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'keyword'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "322b1a5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18872/324778214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keyword'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "df['keyword'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6583d0de",
   "metadata": {},
   "source": [
    "## 3. Checking data types\n",
    "\n",
    "Syntax\n",
    "- `df.dtypes()`\n",
    "- `df.describe()`\n",
    "- `df.describe().show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a9e8278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('keyword', 'string'), ('freq_2021', 'int')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4c3ceab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, keyword: string, freq_2021: string]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9cb53dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|          keyword|         freq_2021|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|            11470|             11470|\n",
      "|   mean|             null| 5.390061028770706|\n",
      "| stddev|             null|13.217850003680276|\n",
      "|    min|               aa|                 1|\n",
      "|    max|zygosaccharomyces|               540|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d13d5cf",
   "metadata": {},
   "source": [
    "## 4. Adding columns\n",
    "\n",
    "Syntax\n",
    "- `df.withColumn('new_col', df['old_col'] + do_something).show()`\n",
    "  - Not an inplace operation\n",
    "- `df = df.withColumn('new_col', df['old_col'] + do_something)`\n",
    "- `df.show()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "500d473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------------+\n",
      "|   keyword|freq_2021|   Scaled freq_2021|\n",
      "+----------+---------+-------------------+\n",
      "|      food|      540|                1.0|\n",
      "|    drying|      341| 0.6314814814814815|\n",
      "|   quality|      264| 0.4888888888888889|\n",
      "|     plant|      214| 0.3962962962962963|\n",
      "|  products|      188|0.34814814814814815|\n",
      "|    higher|      177| 0.3277777777777778|\n",
      "|      data|      177| 0.3277777777777778|\n",
      "|properties|      173|0.32037037037037036|\n",
      "|    health|      171|0.31666666666666665|\n",
      "|     water|      170| 0.3148148148148148|\n",
      "+----------+---------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Add columns in df\n",
    "#df_pyspark.withColumn('Scaled freq_2021', df_pyspark['freq_2021']/540).show(10)\n",
    "df_pyspark = df_pyspark.withColumn('Scaled freq_2021', df_pyspark['freq_2021']/540)\n",
    "df_pyspark.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea4b47",
   "metadata": {},
   "source": [
    "## 5. Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "377c7d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "| keyword|freq_2021|\n",
      "+--------+---------+\n",
      "|    food|      540|\n",
      "|  drying|      341|\n",
      "| quality|      264|\n",
      "|   plant|      214|\n",
      "|products|      188|\n",
      "+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOT inplace operation\n",
    "#df_pyspark.drop('Scaled freq_2021')\n",
    "df_pyspark = df_pyspark.drop('Scaled freq_2021')\n",
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d919ae",
   "metadata": {},
   "source": [
    "## 6. Rename\n",
    "\n",
    "Syntax\n",
    "- `df_pyspark.withColumnRenamed('old_name', 'new_name')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a255c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|freq_word|freq_2021|\n",
      "+---------+---------+\n",
      "|     food|      540|\n",
      "|   drying|      341|\n",
      "|  quality|      264|\n",
      "|    plant|      214|\n",
      "| products|      188|\n",
      "+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOT inplace operation\n",
    "df_pyspark.withColumnRenamed('keyword', 'freq_word').show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
